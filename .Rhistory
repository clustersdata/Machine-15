ii=ii+1
#ii=3
hist(train[ii])
ii=ii+1
#ii=3
hist(train[ii])
ii=ii+1
#ii=3
hist(train[ii])
ii=ii+1
#ii=3
hist(train[ii])
ii=ii+1
#ii=3
hist(train[ii])
ii=ii+1
#ii=3
hist(train[ii])
ii=ii+1
#ii=3
hist(train[ii])
ii=ii+1
#ii=3
hist(train[ii])
ii=ii+1
#ii=3
hist(train[ii])
ii=ii+1
#ii=3
hist(train[ii])
ii=ii+1
ii
head(train[ii])
#ii=3
hist(as.numeric(as.character(train[ii])))
ii=ii+1
#ii=3
hist(as.numeric(as.character(train[ii])))
ii=ii+1
#ii=3
hist(as.numeric(as.character(train[ii])))
ii=ii+1
#ii=3
hist(as.numeric(as.character(train[ii])))
ii=ii+1
as.character(train[ii])
?caret
?preProcess
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv')
# prepare the data
inTrain <- createDataPartition(y = tr$classe,
## the outcome data are needed
+ p = .75,
## The percentage of data in the
## training set
+ list = FALSE)
inTrain <- createDataPartition(y = tr$classe, p = .75,list = FALSE)
str(inTrain)
###################################################
### code chunk number 1: loadLibs
###################################################
library(caret)
library(mlbench)
data(Sonar)
library(pROC)
library(pls)
options(useFancyQuotes = FALSE)
getInfo <- function(what = "Suggests")
{
text <- packageDescription("caret")[what][[1]]
text <- gsub("\n", ", ", text, fixed = TRUE)
text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
#out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
#paste(out, collapse = ", ")
length(eachPkg)
}
###################################################
### code chunk number 2: install (eval = FALSE)
###################################################
## install.packages("caret", dependencies = c("Depends", "Suggests"))
###################################################
### code chunk number 3: SonarSplit
###################################################
library(caret)
library(mlbench)
data(Sonar)
set.seed(107)
inTrain <- createDataPartition(y = Sonar$Class,
## the outcome data are needed
p = .75,
## The percentage of data in the
## training set
list = FALSE)
## The format of the results
## The output is a set of integers for the rows of Sonar
## that belong in the training set.
str(inTrain)
##################################################
### code chunk number 4: SonarDatasets
###################################################
training <- Sonar[ inTrain,]
testing  <- Sonar[-inTrain,]
nrow(training)
nrow(testing)
###################################################
### code chunk number 6: plsFit
###################################################
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
set.seed(123)
plsFit <- train(Class ~ .,
data = training,
method = "pls",
tuneLength = 15,
trControl = ctrl,
metric = "ROC",
preProc = c("center", "scale"))
###################################################
### code chunk number 7: plsPrint
###################################################
plsFit
###################################################
### code chunk number 8: baPlot
###################################################
trellis.par.set(caretTheme())
print(plot(plsFit))
###################################################
### code chunk number 9: plsPred
###################################################
plsClasses <- predict(plsFit, newdata = testing)
str(plsClasses)
plsProbs <- predict(plsFit, newdata = testing, type = "prob")
head(plsProbs)
###################################################
### code chunk number 10: plsCM
###################################################
confusionMatrix(data = plsClasses, testing$Class)
###################################################
### code chunk number 11: rdaFit
###################################################
## To illustrate, a custom grid is used
rdaGrid = data.frame(gamma = (0:4)/4, lambda = 3/4)
set.seed(123)
rdaFit <- train(Class ~ .,
data = training,
method = "rda",
tuneGrid = rdaGrid,
trControl = ctrl,
metric = "ROC")
### R code from vignette source 'caret.Rnw'
###################################################
### code chunk number 1: loadLibs
###################################################
library(caret)
library(mlbench)
data(Sonar)
library(pROC)
library(pls)
options(useFancyQuotes = FALSE)
getInfo <- function(what = "Suggests")
{
text <- packageDescription("caret")[what][[1]]
text <- gsub("\n", ", ", text, fixed = TRUE)
text <- gsub(">=", "$\\\\ge$", text, fixed = TRUE)
eachPkg <- strsplit(text, ", ", fixed = TRUE)[[1]]
eachPkg <- gsub(",", "", eachPkg, fixed = TRUE)
#out <- paste("\\\\pkg{", eachPkg[order(tolower(eachPkg))], "}", sep = "")
#paste(out, collapse = ", ")
length(eachPkg)
}
###################################################
### code chunk number 2: install (eval = FALSE)
###################################################
## install.packages("caret", dependencies = c("Depends", "Suggests"))
###################################################
### code chunk number 3: SonarSplit
###################################################
library(caret)
library(mlbench)
data(Sonar)
set.seed(107)
inTrain <- createDataPartition(y = Sonar$Class,
## the outcome data are needed
p = .75,
## The percentage of data in the
## training set
list = FALSE)
## The format of the results
## The output is a set of integers for the rows of Sonar
## that belong in the training set.
str(inTrain)
###################################################
### code chunk number 4: SonarDatasets
###################################################
training <- Sonar[ inTrain,]
testing  <- Sonar[-inTrain,]
nrow(training)
nrow(testing)
###################################################
### code chunk number 5: plsTune1 (eval = FALSE)
###################################################
## plsFit <- train(Class ~ .,
##                 data = training,
##                 method = "pls",
##                 ## Center and scale the predictors for the training
##                 ## set and all future samples.
##                 preProc = c("center", "scale"))
###################################################
### code chunk number 6: plsFit
###################################################
ctrl <- trainControl(method = "repeatedcv",
repeats = 3,
classProbs = TRUE,
summaryFunction = twoClassSummary)
set.seed(123)
plsFit <- train(Class ~ .,
data = training,
method = "pls",
tuneLength = 15,
trControl = ctrl,
metric = "ROC",
preProc = c("center", "scale"))
###################################################
### code chunk number 7: plsPrint
###################################################
plsFit
###################################################
### code chunk number 8: baPlot
###################################################
trellis.par.set(caretTheme())
print(plot(plsFit))
###################################################
### code chunk number 9: plsPred
###################################################
plsClasses <- predict(plsFit, newdata = testing)
str(plsClasses)
plsProbs <- predict(plsFit, newdata = testing, type = "prob")
head(plsProbs)
###################################################
### code chunk number 10: plsCM
###################################################
confusionMatrix(data = plsClasses, testing$Class)
###################################################
### code chunk number 11: rdaFit
###################################################
## To illustrate, a custom grid is used
rdaGrid = data.frame(gamma = (0:4)/4, lambda = 3/4)
set.seed(123)
rdaFit <- train(Class ~ .,
data = training,
method = "rda",
tuneGrid = rdaGrid,
trControl = ctrl,
metric = "ROC")
## To illustrate, a custom grid is used
rdaGrid = data.frame(gamma = (0:4)/4, lambda = 3/4)
set.seed(123)
rdaFit <- train(Class ~ .,
data = training,
method = "rda",
tuneGrid = rdaGrid,
trControl = ctrl,
metric = "ROC")
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv')
# prepare the data
head(tr)
str(tr[1])
str(tr[2])
levels(tr[2])
unique(tr[2])
levels(tr[2])
factors(tr[2])
factor(tr[2])
str(tr[3])
hist(tr[3])
hist(as.numeric(tr[3]))
hist(unlist(tr[3]))
str(unlist(tr[3]))
str(unlist(tr[3]))
str(unlist(tr[4]))
hist(unlist(tr[4]))
hist(unlist(tr[5]))
str(unlist(tr[5]))
str(tr[5])
str(tr[6])
str(tr[7])
hist(tr[7])
hist(unlist(tr[7]))
hist(unlist(tr[6]))
hist(unlist(tr[8]))
hist(unlist(tr[9]))
hist(unlist(tr[10]))
hist(unlist(tr[11]))
hist(unlist(tr[12]))
str(unlist(tr[12]))
str(as.numeric(tr[12]))
as.numeric(unlist(tr[12]))
hist(as.numeric(unlist(tr[12])))
str(tr[12])
hist(as.numeric(as.character(unlist(tr[12]))))
hist(as.numeric(as.character(unlist(tr[13]))))
hist(as.numeric(as.character(unlist(tr[14]))))
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv')
# prepare the data
hist(as.numeric(as.character(unlist(tr[14]))))
tr$classe
head(tr[,-160])
preProcess(tr[,-160])
is.numeric(tr[,1])
is.numeric(tr[1])
is.numeric(tr[1])
(tr[1])
head(tr[1])
head(tr[,1])
head(tr[,2])
is.numeric(tr[,2])
is.numeric(tr[2])
is.numeric(tr[,2])
is.numeric(tr[,3])
is.numeric(tr[,4])
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv')
# prepare the data
Out<- numeric(160)
for (ii in 1:160)
Out[ii]<- is.numeric(tr[,ii])
PP<-preProcess(tr[,Out])
head(PP)
Out
head(tr[,Out])
head(tr[,1])
head(tr[,2])
head(tr[,4])
head(tr[,5])
head(tr[,6])
Out[6]
Out[5]
Out[4]
Out[2]
?read.csv
tr$max_roll_belt
mean(tr$max_roll_belt, na.rm=T)
hist(tr$max_roll_belt, na.rm=T)
hist(tr$max_roll_belt)
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv')
tr[1]
str(tr[1])
str(tr[2])
str(tr[3])
str(tr[4])
names(str(tr[4]))
attributes(str(tr[4]))
attr(str(tr[4]))
str(tr[4])
?str
ls.str(tr[4])
ls.str(tr[4])[1]
ls.str(tr[4])[2]
ls.str(tr[4])[3]
ls.str(tr[4])[4]
ls.str(tr[4])[1][1]
ls.str(tr[4])[1][2]
ls.str(tr[4])[1]
ls.str(tr[4])[[1]]
ls.str(tr[4])[[2]]
ls.str(tr[4])
ls.str(tr[4])[2]
ls.str(tr[4])[[2]]
ls.str(tr[4])[1][1]
ls.str(tr[4])[1][2]
ls.str(tr[4])[1][3]
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv')
str(str)
str(tr)
ls.str()
rm(PP)
ls.str()
rm(ii)
rm(Out)
ls.str()
ls.str()[1]
ls.str()[2]
ls.str()[3]
ls.str()
ls.str()[[1]]
ls.str()[[1]][1]
ls.str()[[1]][2]
ls.str()
ls.str()
tr[1]
tr[,1]
tr[,2]
tr[,3]
as.numeric(tr[,3])
as.numeric(tr[,4])
as.numeric(tr[,5])
(tr[,5])
(tr[,6])
as.levels(tr[,6])
as.numeric(tr[,6])
as.numeric(tr[,6])
(tr[,6])
(tr[,7])
as.numeric(tr[,7])
head(tr[,7])
head(tr[7])
head(tr[8])
head(tr[9])
head(tr[10])
head(tr[,10])
head(tr[,1])
head(tr[,11])
head(tr[11])
?read.csv
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv2('data/pml-training.csv')
# prepare the data
head(tr)
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv')
# prepare the data
head(tr)
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv', fill=T)
# prepare the data
head(tr)
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv',colClasses = "character")
# prepare the data
head(tr)
# Load training data
library(caret)
library(randomForest)
#
tr<- read.table('data/pml-training.csv')
# prepare the data
head(tr)
tr[1]
# Load training data
library(caret)
library(randomForest)
#
tr<- read.table('data/pml-training.csv', sep=',')
# prepare the data
tr[1]
head(tr)
tr[1]
tr[2]
tr[3]
tr[5]
tr[6]
tr[7]
hist(tr[7])
hist(tr[6])
boxplot(tr[6])
boxplot(tr[,6])
hist(tr[,6])
hist(tr[,7])
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv')
# prepare the data
library(gdata)
read.xls('data/pml-training.csv')
read.xls('data/pml-training.csv')
# Load training data
library(caret)
library(randomForest)
#
tr<- read.csv('data/pml-training.csv')
# prepare the data
