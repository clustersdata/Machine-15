##### Chapter 4: Classification using Naive Bayes --------------------#
## Example: Filtering spam SMS messages ----#
## Step 2: Exploring and preparing the data ---- #
# read the sms data into the sms data frame#
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)
sms_raw
# examine the structure of the sms data#
str(sms_raw)
# convert spam/ham to factor.#
sms_raw$type <- factor(sms_raw$type)#
# examine the type variable more carefully#
str(sms_raw$type)#
table(sms_raw$type)
# build a corpus using the text mining (tm) package#
library(tm)#
sms_corpus <- Corpus(VectorSource(sms_raw$text))
# examine the sms corpus#
print(sms_corpus)#
inspect(sms_corpus[1:3])
# clean up the corpus using tm_map()#
corpus_clean <- tm_map(sms_corpus, tolower)#
corpus_clean <- tm_map(corpus_clean, removeNumbers)#
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())#
corpus_clean <- tm_map(corpus_clean, removePunctuation)#
corpus_clean <- tm_map(corpus_clean, stripWhitespace)#
# examine the clean corpus#
inspect(sms_corpus[1:3])#
inspect(corpus_clean[1:3])
# create a document-term sparse matrix#
sms_dtm <- DocumentTermMatrix(corpus_clean)#
sms_dtm
##### Chapter 4: Classification using Naive Bayes --------------------#
## Example: Filtering spam SMS messages ----#
## Step 2: Exploring and preparing the data ---- #
# read the sms data into the sms data frame#
sms_raw <- read.csv("sms_spam.csv", stringsAsFactors = FALSE)#
# examine the structure of the sms data#
str(sms_raw)#
# convert spam/ham to factor.#
sms_raw$type <- factor(sms_raw$type)#
# examine the type variable more carefully#
str(sms_raw$type)#
table(sms_raw$type)#
# build a corpus using the text mining (tm) package#
library(tm)#
sms_corpus <- Corpus(VectorSource(sms_raw$text))#
# examine the sms corpus#
print(sms_corpus)#
inspect(sms_corpus[1:3])#
# clean up the corpus using tm_map()#
corpus_clean <- tm_map(sms_corpus, tolower)#
corpus_clean <- tm_map(corpus_clean, removeNumbers)#
corpus_clean <- tm_map(corpus_clean, removeWords, stopwords())#
corpus_clean <- tm_map(corpus_clean, removePunctuation)#
corpus_clean <- tm_map(corpus_clean, stripWhitespace)#
# examine the clean corpus#
inspect(sms_corpus[1:3])#
inspect(corpus_clean[1:3])#
# create a document-term sparse matrix#
sms_dtm <- DocumentTermMatrix(corpus_clean)#
sms_dtm
sms_dtm <- DocumentTermMatrix(tm_map(corpus_clean, PlainTextDocument))#
sms_dtm
# creating training and test datasets#
sms_raw_train <- sms_raw[1:4169, ]#
sms_raw_test  <- sms_raw[4170:5559, ]#
sms_dtm_train <- sms_dtm[1:4169, ]#
sms_dtm_test  <- sms_dtm[4170:5559, ]#
sms_corpus_train <- corpus_clean[1:4169]#
sms_corpus_test  <- corpus_clean[4170:5559]#
# check that the proportion of spam is similar#
prop.table(table(sms_raw_train$type))#
prop.table(table(sms_raw_test$type))#
# word cloud visualization#
library(wordcloud)
wordcloud(sms_corpus_train, min.freq = 30, random.order = FALSE)
# subset the training data into spam and ham groups#
spam <- subset(sms_raw_train, type == "spam")#
ham  <- subset(sms_raw_train, type == "ham")#
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))#
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
library(e1071)
